// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
const spec_ident = {__proto__:null,box:10}
export const parser = LRParser.deserialize({
  version: 14,
  states: "%WOYQPOOOOQO'#C_'#C_OqQPO'#CpOOQO'#Co'#CoOYQPO'#CoO!qQPO'#CmOOQO'#Cn'#CnO#OQPO'#CdO#TQPO'#CgOOQO'#Cm'#CmQOQPOOO#YQPO,59[O#_QPO,59ZOOQO,58x,58xOYQPO,59RO#dQPO,59OO#dQPO,59ROOQO1G.v1G.vOOQO1G.u1G.uOOQO1G.m1G.mO#lQPO1G.jO#qQPO1G.mOYQPO7+$UOYQPO7+$XO#vQPO<<GpO#{QPO<<GsO$QQPOAN=[O$VQPOAN=_OYQPOG22vOYQPOG22yOOQOLD(bLD(bOOQOLD(eLD(e",
  stateData: "$[~O_OS`OS~OTROUSOXVO[WOePOfPOhRO~OgZOTdXUdXYdX]dXedXfdXhdXVdX~OTROUSOePOfPOhRO~OY^O]aXVaX~P!`OU_O~OU`O~OSaO~OVbO~OePOfPO~OifO~OigO~OVjO~OVkO~OYlO~OYmO~O",
  goto: "#`ePPfoPPPP!PPP!PPPPPP!Y!o!x#U_UOS^fglm`QOST^fglmQd_Re`_XOS^fglmQYOQ[SQc^QhfQigQnlRom_TOS^fglm^UOS^fglmR]TaROST^fglm",
  nodeNames: "âš  Expression App Identifier Number box ( ) Lambda \\ -> Pi \\/",
  maxTerm: 25,
  skippedNodes: [0],
  repeatNodeCount: 0,
  tokenData: "%i~R`XY!TYZ!fZ[!T]^!fpq!Txy!kyz$Wz{$]}!O$b!Q![$m![!]$r!b!c$w!c!}$|#O#P%[#T#o$|$f$g!T~!YS_~XY!TZ[!Tpq!T$f$g!T~!kO`~~!pcU~qr#{st#{tu#{uv#{vw#{z{#{{|#{}!O#{!O!P#{!P!Q#{!^!_#{!_!`#{!`!a#{!a!b#{!b!c#{#O#P#{#Q#R#{#p#q#{#r#s#{~$OPyz$R~$WOe~~$]OV~~$bOh~~$eP!`!a$h~$mOY~~$rOS~~$wOi~~$|Og~~%RRf~!Q![$|!c!}$|#T#o$|~%aPX~!P!Q%d~%iO[~",
  tokenizers: [0],
  topRules: {"Expression":[0,1]},
  specialized: [{term: 22, get: (value) => spec_ident[value] || -1}],
  tokenPrec: 0
})
